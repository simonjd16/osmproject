{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## After auditing the street names I have added to the expected list based on local knowledge\n",
    "## Corrections are also required to abbreviations present in the data set to correctly map them the expect value\n",
    "\n",
    "import xml.etree.cElementTree as ET\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import pprint\n",
    "\n",
    "OSMFILE = \"Newbury Area OSM 281116.osm\"\n",
    "street_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
    "num_line_street_re = re.compile(r'\\d0?(st|nd|rd|th|)\\s(Line)$', re.IGNORECASE) # Spelling out numbers in streets rather than using numbers\n",
    "nth_re = re.compile(r'\\d\\d?(st|nd|rd|th|)', re.IGNORECASE)\n",
    "nesw_re = re.compile(r'\\s(North|East|South|West)$')\n",
    "\n",
    "expected = [\"Street\", \"Avenue\", \"Boulevard\", \"Drive\", \"Court\", \"Place\", \"Square\", \"Lane\", \"Road\", \n",
    "            \"Trail\", \"Parkway\", \"Commons\", \"Close\", \"Gardens\", \"Hill\", \"Way\", \"Park\", \"Centre\", \n",
    "            \"Common\", \"Crescent\", \"Fields\", \"Roundabout\", \"Row\", \"Ride\", \"View\", \"Walk\",\n",
    "            \"Broadway\", \"Down\", \"End\", \"Grove\", \"Cornfields\", \"Eastcourt\", \"Green\", \"Link\",\n",
    "            \"Mill\", \"Newfound\", \"A339\", \"Fosbury\", \"Glebe\", \"Hailey\", \"Rookery\", \"Smithy\", \"Parade\",\n",
    "            \"Arcade\", \"Estate\", \"Mall\", \"Rise\", \"Horse\", \"West\", \"Mead\"]\n",
    "\n",
    "mapping = { \n",
    "            \"Rd\" : \"Road\",\n",
    "            \"Road,\" : \"Road\",\n",
    "            \"Steet\" : \"Street\",\n",
    "            \"Rd'\" : \"Road\",\n",
    "            \"Road,\" : \"Road\",\n",
    "            \"Steet\" : \"Street\",\n",
    "            \"Ave\" : \"Avenue\",\n",
    "            \"Sr\" : \"Street\"\n",
    "            }  \n",
    "\n",
    "street_mapping = { \n",
    "            \"Rd\" : \"Road\",\n",
    "            \"Road,\" : \"Road\",\n",
    "            \"Steet\" : \"Street\",\n",
    "            \"Rd'\" : \"Road\",\n",
    "            \"Road,\" : \"Road\",\n",
    "            \"Steet\" : \"Street\",\n",
    "            \"Ave\" : \"Avenue\",\n",
    "            \"Sr\" : \"Street\"\n",
    "            }  \n",
    "\n",
    "num_line_mapping = {\n",
    "                     \"1st\": \"First\",\n",
    "                     \"2nd\": \"Second\",\n",
    "                     \"3rd\": \"Third\",\n",
    "                     \"4th\": \"Fourth\",\n",
    "                     \"5th\": \"Fifth\",\n",
    "                     \"6th\": \"Sixth\",\n",
    "                     \"7th\": \"Seventh\",\n",
    "                     \"8th\": \"Eighth\",\n",
    "                     \"9th\": \"Ninth\",\n",
    "                     \"10th\": \"Tenth\"\n",
    "                   }\n",
    "\n",
    "def audit_street_type(street_types, street_name):\n",
    "    m = street_type_re.search(street_name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        if street_type not in expected:\n",
    "            street_types[street_type].add(street_name)\n",
    "\n",
    "def is_street_name(elem):\n",
    "    return (elem.attrib['k'] == \"addr:street\")  \n",
    "\n",
    "def audit_street(OSMFILE):\n",
    "    osm_file = open(OSMFILE, \"r\")\n",
    "    street_types = defaultdict(set)\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):      \n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_street_name(tag):\n",
    "                    audit_street_type(street_types, tag.attrib['v'])\n",
    "    osm_file.close\n",
    "    return street_types\n",
    "  \n",
    "\n",
    "def update_name(name):\n",
    "    \"\"\"\n",
    "    Clean street name for insertion into SQL database\n",
    "    \"\"\"\n",
    "    if num_line_street_re.match(name):\n",
    "        nth = nth_re.search(name)\n",
    "        name = num_line_mapping[nth.group(0)] + \" Line\"\n",
    "        return name\n",
    "    \n",
    "    elif name == \"York & Durham Line\" or name == \"York/Durham Line\":\n",
    "        name = \"York-Durham Line\"\n",
    "        return name\n",
    "\n",
    "    else:\n",
    "        original_name = name\n",
    "        for key in mapping.keys():\n",
    "            # Only replace when mapping key match (e.g. \"St.\") is found at end of name\n",
    "            type_fix_name = re.sub(r'\\s' + re.escape(key) + r'$', ' ' + mapping[key], original_name)\n",
    "            nesw = nesw_re.search(type_fix_name)\n",
    "            if nesw is not None:\n",
    "                for key in street_mapping.keys():\n",
    "                    # Do not update correct names like St. Clair Avenue West\n",
    "                    dir_fix_name = re.sub(r'\\s' + re.escape(key) + re.escape(nesw.group(0)), \" \" + street_mapping[key] + nesw.group(0), type_fix_name)\n",
    "                    if dir_fix_name != type_fix_name:\n",
    "                        # print original_name + \"=>\" + type_fix_name + \"=>\" + dir_fix_name\n",
    "                        return dir_fix_name\n",
    "            if type_fix_name != original_name:\n",
    "                # print original_name + \"=>\" + type_fix_name\n",
    "                return type_fix_name\n",
    "    # Check if avenue, road, street, etc. are capitalized\n",
    "    last_word = original_name.rsplit(None, 1)[-1]\n",
    "    if last_word.islower():\n",
    "        original_name = re.sub(last_word, last_word.title(), original_name)\n",
    "    return original_name\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Due to problems with the schema.py loading, I used for forums to assist with the problem\n",
    "## It had occured before and the solution given was to paste the code in and remove the import schema statement\n",
    "\n",
    "# Note: The schema is stored in a .py file in order to take advantage of the\n",
    "# int() and float() type coercion functions. Otherwise it could easily stored as\n",
    "# as JSON or another serialized format.\n",
    "\n",
    "schema = {\n",
    "    'node': {\n",
    "        'type': 'dict',\n",
    "        'schema': {\n",
    "            'id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'lat': {'required': True, 'type': 'float', 'coerce': float},\n",
    "            'lon': {'required': True, 'type': 'float', 'coerce': float},\n",
    "            'user': {'required': True, 'type': 'string'},\n",
    "            'uid': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'version': {'required': True, 'type': 'string'},\n",
    "            'changeset': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'timestamp': {'required': True, 'type': 'string'}\n",
    "        }\n",
    "    },\n",
    "    'node_tags': {\n",
    "        'type': 'list',\n",
    "        'schema': {\n",
    "            'type': 'dict',\n",
    "            'schema': {\n",
    "                'id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "                'key': {'required': True, 'type': 'string'},\n",
    "                'value': {'required': True, 'type': 'string'},\n",
    "                'type': {'required': True, 'type': 'string'}\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    'way': {\n",
    "        'type': 'dict',\n",
    "        'schema': {\n",
    "            'id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'user': {'required': True, 'type': 'string'},\n",
    "            'uid': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'version': {'required': True, 'type': 'string'},\n",
    "            'changeset': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'timestamp': {'required': True, 'type': 'string'}\n",
    "        }\n",
    "    },\n",
    "    'way_nodes': {\n",
    "        'type': 'list',\n",
    "        'schema': {\n",
    "            'type': 'dict',\n",
    "            'schema': {\n",
    "                'id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "                'node_id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "                'position': {'required': True, 'type': 'integer', 'coerce': int}\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    'way_tags': {\n",
    "        'type': 'list',\n",
    "        'schema': {\n",
    "            'type': 'dict',\n",
    "            'schema': {\n",
    "                'id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "                'key': {'required': True, 'type': 'string'},\n",
    "                'value': {'required': True, 'type': 'string'},\n",
    "                'type': {'required': True, 'type': 'string'}\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Preparing the data for transfering into SQL\n",
    "import csv\n",
    "import codecs\n",
    "import re\n",
    "import xml.etree.cElementTree as ET\n",
    "\n",
    "import cerberus\n",
    "\n",
    "OSM_PATH = \"Newbury Area OSM 31102016.osm\"\n",
    "\n",
    "NODES_PATH = \"nodes.csv\"\n",
    "NODE_TAGS_PATH = \"nodes_tags.csv\"\n",
    "WAYS_PATH = \"ways.csv\"\n",
    "WAY_NODES_PATH = \"ways_nodes.csv\"\n",
    "WAY_TAGS_PATH = \"ways_tags.csv\"\n",
    "\n",
    "LOWER_COLON = re.compile(r'^([a-z]|_)+:([a-z]|_)+')\n",
    "PROBLEMCHARS = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "POSTCODE = re.compile(r'[A-z]\\d[A-z]\\s?\\d[A-z]\\d')\n",
    "\n",
    "SCHEMA = schema\n",
    "\n",
    "# Make sure the fields order in the csvs matches the column order in the sql table schema\n",
    "NODE_FIELDS = ['id', 'lat', 'lon', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "NODE_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_FIELDS = ['id', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "WAY_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_NODES_FIELDS = ['id', 'node_id', 'position']\n",
    "\n",
    "expected = [\"Street\", \"Avenue\", \"Boulevard\", \"Drive\", \"Court\", \"Place\", \"Square\", \"Lane\", \"Road\", \n",
    "            \"Trail\", \"Parkway\", \"Commons\", \"Close\", \"Gardens\", \"Hill\", \"Way\", \"Park\", \"Centre\", \n",
    "            \"Common\", \"Crescent\", \"Fields\", \"Roundabout\", \"Row\", \"Ride\", \"View\", \"Walk\",\n",
    "            \"Broadway\", \"Down\", \"End\", \"Grove\", \"Cornfields\", \"Eastcourt\", \"Green\", \"Link\",\n",
    "            \"Mill\", \"Newfound\", \"A339\", \"Fosbury\", \"Glebe\", \"Hailey\", \"Rookery\", \"Smithy\", \"Parade\",\n",
    "            \"Arcade\", \"Estate\", \"Mall\", \"Rise\", \"Horse\", \"West\", \"Mead\"]\n",
    "\n",
    "mapping = { \n",
    "            \"Rd\" : \"Road\",\n",
    "            \"Road,\" : \"Road\",\n",
    "            \"Steet\" : \"Street\",\n",
    "            \"Rd'\" : \"Road\",\n",
    "            \"Road,\" : \"Road\",\n",
    "            \"Steet\" : \"Street\",\n",
    "            \"Ave\" : \"Avenue\",\n",
    "            \"Sr\" : \"Street\"\n",
    "            }  \n",
    "\n",
    "def audit_street_type(street_types, street_name):\n",
    "    m = street_type_re.search(street_name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        if street_type not in expected:\n",
    "            street_types[street_type].add(street_name)\n",
    "\n",
    "def is_street_name(elem):\n",
    "    return (elem.attrib['k'] == \"addr:street\")  \n",
    "\n",
    "def audit(OSMFILE):\n",
    "    osm_file = open(OSMFILE, \"r\")\n",
    "    street_types = defaultdict(set)\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):      \n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_street_name(tag):\n",
    "                    audit_street_type(street_types, tag.attrib['v'])\n",
    "    osm_file.close()\n",
    "    return street_types\n",
    "\n",
    "def load_new_tag(element, secondary, default_tag_type):\n",
    "    \"\"\"\n",
    "    Load a new tag dict to go into the list of dicts for way_tags, node_tags\n",
    "    \"\"\"\n",
    "    new = {}\n",
    "    new['id'] = element.attrib['id']\n",
    "    if \":\" not in secondary.attrib['k']:\n",
    "        new['key'] = secondary.attrib['k']\n",
    "        new['type'] = default_tag_type\n",
    "    else:\n",
    "        post_colon = secondary.attrib['k'].index(\":\") + 1\n",
    "        new['key'] = secondary.attrib['k'][post_colon:]\n",
    "        new['type'] = secondary.attrib['k'][:post_colon - 1]\n",
    "\n",
    "    # Cleaning and loading values of various keys\n",
    "    if is_street_name(secondary):\n",
    "        # Why don't i need to use mapping, street_mapping,\n",
    "        # and num_line_mapping dicts  as params?\n",
    "        street_name = update_name(secondary.attrib['v'])\n",
    "        new['value'] = street_name\n",
    "        \n",
    "    else:\n",
    "        new['value'] = secondary.attrib['v']\n",
    "    \n",
    "    return new\n",
    "\n",
    "def shape_element(element, node_attr_fields=NODE_FIELDS, way_attr_fields=WAY_FIELDS,\n",
    "                  problem_chars=PROBLEMCHARS, default_tag_type='regular'):\n",
    "    \"\"\"Clean and shape node or way XML element to Python dict\"\"\"\n",
    "\n",
    "    node_attribs = {}\n",
    "    way_attribs = {}\n",
    "    way_nodes = []\n",
    "    tags = []  # Handle secondary tags the same way for both node and way elements\n",
    "\n",
    "    if element.tag == 'node':\n",
    "        for attrib, value in element.attrib.iteritems():\n",
    "            if attrib in node_attr_fields:\n",
    "                node_attribs[attrib] = value\n",
    "        \n",
    "        # For elements within the top element\n",
    "        for secondary in element.iter():\n",
    "            if secondary.tag == 'tag':\n",
    "                if problem_chars.match(secondary.attrib['k']) is not None:\n",
    "                    continue\n",
    "                else:\n",
    "                    new = load_new_tag(element, secondary, default_tag_type)\n",
    "                    if new is not None:\n",
    "                        tags.append(new)\n",
    "        return {'node': node_attribs, 'node_tags': tags}\n",
    "    \n",
    "    elif element.tag == 'way':\n",
    "        for attrib, value in element.attrib.iteritems():\n",
    "            if attrib in way_attr_fields:\n",
    "                way_attribs[attrib] = value\n",
    "\n",
    "        counter = 0\n",
    "        for secondary in element.iter():\n",
    "            if secondary.tag == 'tag':\n",
    "                if problem_chars.match(secondary.attrib['k']) is not None:\n",
    "                    continue\n",
    "                else:\n",
    "                    new = load_new_tag(element, secondary, default_tag_type)\n",
    "                    if new is not None:\n",
    "                        tags.append(new)\n",
    "            elif secondary.tag == 'nd':\n",
    "                newnd = {}\n",
    "                newnd['id'] = element.attrib['id']\n",
    "                newnd['node_id'] = secondary.attrib['ref']\n",
    "                newnd['position'] = counter\n",
    "                counter += 1\n",
    "                way_nodes.append(newnd)\n",
    "        \n",
    "        return {'way': way_attribs, 'way_nodes': way_nodes, 'way_tags': tags}\n",
    "\n",
    "\n",
    "# ================================================== #\n",
    "#               Helper Functions                     #\n",
    "# ================================================== #\n",
    "def get_element(osm_file, tags=('node', 'way', 'relation')):\n",
    "    \"\"\"Yield element if it is the right type of tag\"\"\"\n",
    "\n",
    "    context = ET.iterparse(osm_file, events=('start', 'end'))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            yield elem\n",
    "            root.clear()\n",
    "\n",
    "\n",
    "def validate_element(element, validator, schema=SCHEMA):\n",
    "    \"\"\"Raise ValidationError if element does not match schema\"\"\"\n",
    "    if validator.validate(element, schema) is not True:\n",
    "        field, errors = next(validator.errors.iteritems())\n",
    "        message_string = \"\\nElement of type '{0}' has the following errors:\\n{1}\"\n",
    "        error_strings = (\n",
    "            \"{0}: {1}\".format(k, v if isinstance(v, str) else \", \".join(v))\n",
    "            for k, v in errors.iteritems()\n",
    "        )\n",
    "        raise cerberus.ValidationError(\n",
    "            message_string.format(field, \"\\n\".join(error_strings))\n",
    "        )\n",
    "\n",
    "\n",
    "class UnicodeDictWriter(csv.DictWriter, object):\n",
    "    \"\"\"Extend csv.DictWriter to handle Unicode input\"\"\"\n",
    "\n",
    "    def writerow(self, row):\n",
    "        super(UnicodeDictWriter, self).writerow({\n",
    "            k: (v.encode('utf-8') if isinstance(v, unicode) else v) for k, v in row.iteritems()\n",
    "        })\n",
    "\n",
    "    def writerows(self, rows):\n",
    "        for row in rows:\n",
    "            self.writerow(row)\n",
    "\n",
    "\n",
    "# ================================================== #\n",
    "#               Main Function                        #\n",
    "# ================================================== #\n",
    "def process_map(file_in, validate):\n",
    "    \"\"\"Iteratively process each XML element and write to csv(s)\"\"\"\n",
    "\n",
    "    with codecs.open(NODES_PATH, 'w') as nodes_file, \\\n",
    "         codecs.open(NODE_TAGS_PATH, 'w') as nodes_tags_file, \\\n",
    "         codecs.open(WAYS_PATH, 'w') as ways_file, \\\n",
    "         codecs.open(WAY_NODES_PATH, 'w') as way_nodes_file, \\\n",
    "         codecs.open(WAY_TAGS_PATH, 'w') as way_tags_file:\n",
    "\n",
    "        nodes_writer = UnicodeDictWriter(nodes_file, NODE_FIELDS)\n",
    "        node_tags_writer = UnicodeDictWriter(nodes_tags_file, NODE_TAGS_FIELDS)\n",
    "        ways_writer = UnicodeDictWriter(ways_file, WAY_FIELDS)\n",
    "        way_nodes_writer = UnicodeDictWriter(way_nodes_file, WAY_NODES_FIELDS)\n",
    "        way_tags_writer = UnicodeDictWriter(way_tags_file, WAY_TAGS_FIELDS)\n",
    "\n",
    "        nodes_writer.writeheader()\n",
    "        node_tags_writer.writeheader()\n",
    "        ways_writer.writeheader()\n",
    "        way_nodes_writer.writeheader()\n",
    "        way_tags_writer.writeheader()\n",
    "\n",
    "        validator = cerberus.Validator()\n",
    "\n",
    "        for element in get_element(file_in, tags=('node', 'way')):\n",
    "            el = shape_element(element)\n",
    "            if el:\n",
    "                if validate is True:\n",
    "                    validate_element(el, validator)\n",
    "\n",
    "                if element.tag == 'node':\n",
    "                    nodes_writer.writerow(el['node'])\n",
    "                    node_tags_writer.writerows(el['node_tags'])\n",
    "                elif element.tag == 'way':\n",
    "                    ways_writer.writerow(el['way'])\n",
    "                    way_nodes_writer.writerows(el['way_nodes'])\n",
    "                    way_tags_writer.writerows(el['way_tags'])\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Note: Validation is ~ 10X slower. For the project consider using a small\n",
    "    # sample of the map when validating.\n",
    "    process_map(OSM_PATH, validate=True)\n",
    "\n",
    "####"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
